{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prisoners Dilemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5UtIxDSlFkAz",
        "outputId": "862b1f1f-b8d8-4f0a-b4c0-1d88fa14adf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Collecting pygame==2.1.0 (from gym[classic_control])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed pygame-2.1.0\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m909.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-rl2) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-rl2) (3.2.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n",
            "Requirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# !pip install gym[classic_control]\n",
        "# !pip install keras-rl2\n",
        "# !pip install protobuf==3.20.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "45zLfwjI0iOa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as k\n",
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras import __version__\n",
        "tf.keras.__version__ = __version__\n",
        "\n",
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "\n",
        "\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, MultiBinary\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version\n",
            "----------------------------- ---------\n",
            "absl-py                       1.4.0\n",
            "aiohttp                       3.8.5\n",
            "aiosignal                     1.3.1\n",
            "altair                        5.3.0\n",
            "asttokens                     2.2.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "attrs                         23.1.0\n",
            "awkward                       2.6.6\n",
            "awkward-cpp                   35\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.12.2\n",
            "blinker                       1.8.2\n",
            "cachetools                    5.3.2\n",
            "calmjs.parse                  1.3.1\n",
            "cernopendata-client           0.3.0\n",
            "certifi                       2023.5.7\n",
            "charset-normalizer            3.1.0\n",
            "click                         8.1.6\n",
            "cloudpickle                   3.0.0\n",
            "colorama                      0.4.6\n",
            "comm                          0.1.2\n",
            "contourpy                     1.0.7\n",
            "cramjam                       2.8.3\n",
            "cycler                        0.11.0\n",
            "debugpy                       1.6.6\n",
            "decorator                     5.1.1\n",
            "distlib                       0.3.8\n",
            "dm-tree                       0.1.8\n",
            "EasyProcess                   1.1\n",
            "entrypoint2                   1.1\n",
            "et-xmlfile                    1.1.0\n",
            "executing                     1.2.0\n",
            "filelock                      3.12.2\n",
            "flatbuffers                   23.5.26\n",
            "fonttools                     4.38.0\n",
            "frozenlist                    1.4.0\n",
            "fsspec                        2024.6.1\n",
            "fsspec_xrootd                 0.3.0\n",
            "gast                          0.4.0\n",
            "gitdb                         4.0.11\n",
            "GitPython                     3.1.43\n",
            "google-auth                   2.23.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-pasta                  0.2.0\n",
            "graphviz                      0.20.3\n",
            "grpcio                        1.59.3\n",
            "gTTS                          2.3.2\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.10.0\n",
            "hijri-converter               2.3.1\n",
            "hijridate                     2.3.0\n",
            "hls4ml                        0.8.1\n",
            "idna                          3.4\n",
            "importlib_metadata            8.0.0\n",
            "imutils                       0.5.4\n",
            "ipykernel                     6.21.2\n",
            "ipython                       8.11.0\n",
            "isodate                       0.6.1\n",
            "jedi                          0.18.2\n",
            "Jinja2                        3.1.2\n",
            "joblib                        1.4.2\n",
            "jsonschema                    4.22.0\n",
            "jsonschema-specifications     2023.12.1\n",
            "jupyter_client                8.0.3\n",
            "jupyter_core                  5.2.0\n",
            "keras                         2.11.0\n",
            "keras-rl2                     1.0.5\n",
            "keras-tuner                   1.4.7\n",
            "kiwisolver                    1.4.4\n",
            "kt-legacy                     1.0.5\n",
            "libclang                      16.0.6\n",
            "lightgbm                      4.5.0\n",
            "Markdown                      3.5.1\n",
            "markdown-it-py                3.0.0\n",
            "MarkupSafe                    2.1.3\n",
            "matplotlib                    3.7.1\n",
            "matplotlib-inline             0.1.6\n",
            "mdurl                         0.1.2\n",
            "memory-profiler               0.61.0\n",
            "ml-dtypes                     0.2.0\n",
            "MouseInfo                     0.1.3\n",
            "mplhep                        0.3.50\n",
            "mplhep-data                   0.0.3\n",
            "mpmath                        1.3.0\n",
            "mss                           9.0.1\n",
            "multidict                     6.0.4\n",
            "Naked                         0.1.32\n",
            "nest-asyncio                  1.5.6\n",
            "networkx                      3.0\n",
            "numpy                         1.24.2\n",
            "oauthlib                      3.2.2\n",
            "onnx                          1.12.0\n",
            "openai                        0.27.8\n",
            "opencv-python-headless        4.9.0.80\n",
            "openpyxl                      3.1.5\n",
            "opt-einsum                    3.3.0\n",
            "packaging                     23.0\n",
            "pandas                        2.1.4\n",
            "parse                         1.6.5\n",
            "parso                         0.8.3\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        9.4.0\n",
            "pip                           22.2.2\n",
            "platformdirs                  4.2.2\n",
            "ply                           3.11\n",
            "prompt-toolkit                3.0.38\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.9.4\n",
            "pure-eval                     0.2.2\n",
            "pyarrow                       16.1.0\n",
            "pyasn1                        0.5.1\n",
            "pyasn1-modules                0.3.0\n",
            "PyAutoGUI                     0.9.54\n",
            "pycryptodome                  3.20.0\n",
            "pydeck                        0.9.1\n",
            "pyDigitalWaveTools            1.1\n",
            "pydot                         2.0.0\n",
            "pygame                        2.5.0\n",
            "PyGetWindow                   0.0.9\n",
            "Pygments                      2.14.0\n",
            "PyMsgBox                      1.0.9\n",
            "pyparser                      1.0\n",
            "pyparsing                     3.0.9\n",
            "pyperclip                     1.8.2\n",
            "PyRect                        0.2.0\n",
            "pyscreenshot                  3.1\n",
            "PyScreeze                     0.1.29\n",
            "python-dateutil               2.8.2\n",
            "pytweening                    1.0.7\n",
            "pytz                          2023.3\n",
            "pywin32                       305\n",
            "PyYAML                        6.0\n",
            "pyzmq                         25.0.0\n",
            "QKeras                        0.9.0\n",
            "rdflib                        7.0.0\n",
            "referencing                   0.35.1\n",
            "requests                      2.31.0\n",
            "requests-oauthlib             1.3.1\n",
            "rich                          13.7.1\n",
            "rpds-py                       0.18.1\n",
            "rsa                           4.9\n",
            "scikit-learn                  1.5.0\n",
            "scipy                         1.11.0\n",
            "seaborn                       0.12.2\n",
            "setuptools                    63.2.0\n",
            "shellescape                   3.8.1\n",
            "six                           1.16.0\n",
            "smmap                         5.0.1\n",
            "soupsieve                     2.5\n",
            "SPARQLWrapper                 2.0.0\n",
            "stack-data                    0.6.2\n",
            "streamlit                     1.35.0\n",
            "supervision                   0.10.0\n",
            "sympy                         1.12\n",
            "tabulate                      0.9.0\n",
            "tenacity                      8.3.0\n",
            "tensorboard                   2.11.2\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.11.1\n",
            "tensorflow-estimator          2.11.0\n",
            "tensorflow-intel              2.11.1\n",
            "tensorflow-io-gcs-filesystem  0.31.0\n",
            "tensorflow-model-optimization 0.8.0\n",
            "termcolor                     2.3.0\n",
            "threadpoolctl                 3.5.0\n",
            "toml                          0.10.2\n",
            "toolz                         0.12.1\n",
            "torch                         2.0.1\n",
            "torchvision                   0.15.2\n",
            "tornado                       6.2\n",
            "tqdm                          4.65.0\n",
            "traitlets                     5.9.0\n",
            "typing_extensions             4.6.3\n",
            "tzdata                        2023.3\n",
            "uhi                           0.4.0\n",
            "ultralytics                   8.0.123\n",
            "uproot                        5.3.9\n",
            "urllib3                       2.0.3\n",
            "virtualenv                    20.26.2\n",
            "watchdog                      4.0.1\n",
            "wcwidth                       0.2.6\n",
            "Werkzeug                      3.0.1\n",
            "wheel                         0.41.3\n",
            "wrapt                         1.14.1\n",
            "xgboost                       2.1.1\n",
            "yarl                          1.9.2\n",
            "zipp                          3.19.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\mohammad doleh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOHZ-lWVFkA1"
      },
      "source": [
        "# Setting Up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slqrNaZxkpyj",
        "outputId": "8618ed71-bdfe-43c2-bcf4-9624dd54fa8d"
      },
      "outputs": [],
      "source": [
        "def tit_for_tat(round,opp_move):\n",
        "  if round == 200:\n",
        "    return 1\n",
        "  else:\n",
        "    return opp_move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0_k-aGaSlk88"
      },
      "outputs": [],
      "source": [
        "def cooperate():\n",
        "  return 1\n",
        "\n",
        "def defect():\n",
        "  return 0\n",
        "\n",
        "def rand():\n",
        "  return random.randint(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qJ-_QaSWmrHS"
      },
      "outputs": [],
      "source": [
        "def tit_for_two_tat(round, opp_move1, opp_move2):\n",
        "  if round >= 199 or opp_move1 == 1 or opp_move2 == 1:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2OsXZr5PoCQY"
      },
      "outputs": [],
      "source": [
        "def grudger(defected):\n",
        "  if defected:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aKwESrgpo-_l"
      },
      "outputs": [],
      "source": [
        "def pavlov(round, last_move,opp_move):\n",
        "  if round == 200:\n",
        "    return 1\n",
        "  elif last_move == opp_move or (last_move == 0 and opp_move == 1):\n",
        "    return last_move\n",
        "  elif last_move == 1 and opp_move == 0:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y0fPJBILqAb0"
      },
      "outputs": [],
      "source": [
        "def soft_grudger(last_defect):\n",
        "  if last_defect < 4:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UvA-jcztroSv"
      },
      "outputs": [],
      "source": [
        "def fortress(round, opp_move1, opp_move2):\n",
        "  if round == 200 or opp_move1 == 0 or opp_move2 == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z25hJ-ptsWSc"
      },
      "outputs": [],
      "source": [
        "def alternator(round,last_move):\n",
        "  if round == 200 or last_move == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cWeLDrvetS04"
      },
      "outputs": [],
      "source": [
        "def sneaky(round,opp_move):\n",
        "  dice=random.randint(0,9)\n",
        "  if round == 200:\n",
        "    return 1\n",
        "  elif dice == 0:\n",
        "    return 0;\n",
        "  else:\n",
        "    return opp_move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uF5DyEIEYxCu"
      },
      "outputs": [],
      "source": [
        "def custom(round):\n",
        "  if round%4 == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iijDpCg0IySw"
      },
      "outputs": [],
      "source": [
        "class PrisonEnv(Env):\n",
        "    def __init__(self):\n",
        "        self.action_space = Discrete(2)\n",
        "        self.observation_space = MultiBinary(10)\n",
        "        self.round = 200\n",
        "        self.state = np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,-1])\n",
        "        self.opp_strategy = random.randint(0,10)\n",
        "        self.opp_move1=1\n",
        "        self.opp_move2=1\n",
        "        self.last_move1=self.state[0]\n",
        "        self.last_move2=self.state[1]\n",
        "        self.opp_defected=False\n",
        "        self.user_defected=False\n",
        "        self.last_defect= np.Infinity\n",
        "        self.opp_last_defect= np.Infinity\n",
        "        self.move=1\n",
        "        self.opp_move=1\n",
        "\n",
        "        self.opp_score=0\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        self.opp_move2=self.opp_move1\n",
        "        self.opp_move1=self.opp_move\n",
        "        self.last_move2=self.state[1]\n",
        "        self.last_move1=self.state[0]\n",
        "\n",
        "        self.move=action\n",
        "\n",
        "\n",
        "\n",
        "        if self.opp_strategy == 0:\n",
        "          opp_move=tit_for_tat(self.round,self.last_move1)\n",
        "        elif self.opp_strategy == 1:\n",
        "          opp_move=cooperate()\n",
        "        elif self.opp_strategy == 2:\n",
        "          opp_move=sneaky(self.round, self.last_move1)\n",
        "        elif self.opp_strategy == 3:\n",
        "          opp_move=rand()\n",
        "        elif self.opp_strategy == 4:\n",
        "          opp_move=tit_for_two_tat(self.round,self.last_move1, self.last_move2)\n",
        "        elif self.opp_strategy == 5:\n",
        "          opp_move=grudger(self.user_defected)\n",
        "        elif self.opp_strategy == 6:\n",
        "          opp_move=pavlov(self.round,self.opp_move1, self.last_move1)\n",
        "        elif self.opp_strategy == 7:\n",
        "          opp_move=soft_grudger(self.last_defect)\n",
        "        elif self.opp_strategy == 8:\n",
        "          opp_move=fortress(self.round, self.last_move1, self.last_move2)\n",
        "        elif self.opp_strategy == 9:\n",
        "          opp_move=alternator(self.round,self.opp_move1)\n",
        "        elif self.opp_strategy == 10:\n",
        "          opp_move = custom(self.round)\n",
        "\n",
        "\n",
        "        temp = np.array(list(self.state))\n",
        "\n",
        "        for i in range(1,10):\n",
        "          self.state[i] = temp[i-1]\n",
        "        self.state[0] = self.move\n",
        "\n",
        "\n",
        "        if opp_move == 0:\n",
        "          self.opp_defected=True\n",
        "          self.opp_last_defect=0\n",
        "        else:\n",
        "          self.opp_last_defect += 1\n",
        "\n",
        "        if self.move == 0:\n",
        "          self.user_defected=True\n",
        "          self.last_defect=0\n",
        "        else:\n",
        "          self.last_defect += 1\n",
        "\n",
        "        if self.move == 1 and opp_move == 1:\n",
        "          reward = 3\n",
        "          self.opp_score += 3\n",
        "        elif self.move == 1 and opp_move == 0:\n",
        "          reward = 0\n",
        "          self.opp_score += 5\n",
        "        elif self.move == 0 and opp_move == 1:\n",
        "          reward = 5\n",
        "          self.opp_score += 0\n",
        "        elif self.move == 0 and opp_move == 0:\n",
        "          reward = 1\n",
        "          self.opp_score += 1\n",
        "\n",
        "        self.round -= 1\n",
        "\n",
        "        if self.round <= 0:\n",
        "            done = True\n",
        "\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        info = {'opp_score':self.opp_score}\n",
        "\n",
        "\n",
        "\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.round = 200\n",
        "        self.state = np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,-1])\n",
        "        self.opp_strategy = random.randint(0,10)\n",
        "        self.opp_move1=1\n",
        "        self.opp_move2=1\n",
        "        self.last_move1=self.state[0]\n",
        "        self.last_move2=self.state[1]\n",
        "        self.opp_defected=False\n",
        "        self.user_defected=False\n",
        "        self.last_defect= np.Infinity\n",
        "        self.opp_last_defect= np.Infinity\n",
        "        self.move=1\n",
        "        self.opp_move=1\n",
        "\n",
        "        self.opp_score = 0\n",
        "\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsEP4kkTOLqm",
        "outputId": "a3d250df-00ca-4783-f96b-92bdcbf3117b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = PrisonEnv()\n",
        "env.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQPB8asti9xu",
        "outputId": "fd2854d5-efa8-45a7-d44d-16fc29657dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = env.state.reshape(-1, 10)\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test on Random Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0r3lysXOrjZ",
        "outputId": "7aafde9e-2419-40da-8ed6-d19e3eda56a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode:1 Score:640 Info:{'opp_score': 360}\n",
            "Episode:2 Score:413 Info:{'opp_score': 478}\n",
            "Episode:3 Score:109 Info:{'opp_score': 609}\n",
            "Episode:4 Score:405 Info:{'opp_score': 465}\n",
            "Episode:5 Score:156 Info:{'opp_score': 576}\n",
            "Episode:6 Score:635 Info:{'opp_score': 390}\n",
            "Episode:7 Score:828 Info:{'opp_score': 258}\n",
            "Episode:8 Score:429 Info:{'opp_score': 424}\n",
            "Episode:9 Score:623 Info:{'opp_score': 383}\n",
            "Episode:10 Score:637 Info:{'opp_score': 367}\n",
            "Episode:11 Score:138 Info:{'opp_score': 593}\n",
            "Episode:12 Score:622 Info:{'opp_score': 362}\n",
            "Episode:13 Score:87 Info:{'opp_score': 662}\n",
            "Episode:14 Score:120 Info:{'opp_score': 535}\n",
            "Episode:15 Score:806 Info:{'opp_score': 291}\n",
            "Episode:16 Score:462 Info:{'opp_score': 457}\n",
            "Episode:17 Score:629 Info:{'opp_score': 349}\n",
            "Episode:18 Score:132 Info:{'opp_score': 592}\n",
            "Episode:19 Score:156 Info:{'opp_score': 581}\n",
            "Episode:20 Score:826 Info:{'opp_score': 261}\n",
            "Episode:21 Score:286 Info:{'opp_score': 531}\n",
            "Episode:22 Score:132 Info:{'opp_score': 602}\n",
            "Episode:23 Score:592 Info:{'opp_score': 427}\n",
            "Episode:24 Score:106 Info:{'opp_score': 611}\n",
            "Episode:25 Score:454 Info:{'opp_score': 454}\n",
            "Episode:26 Score:299 Info:{'opp_score': 534}\n",
            "Episode:27 Score:603 Info:{'opp_score': 368}\n",
            "Episode:28 Score:93 Info:{'opp_score': 643}\n",
            "Episode:29 Score:812 Info:{'opp_score': 282}\n",
            "Episode:30 Score:412 Info:{'opp_score': 452}\n",
            "Episode:31 Score:146 Info:{'opp_score': 596}\n",
            "Episode:32 Score:439 Info:{'opp_score': 434}\n",
            "Episode:33 Score:421 Info:{'opp_score': 476}\n",
            "Episode:34 Score:286 Info:{'opp_score': 541}\n",
            "Episode:35 Score:263 Info:{'opp_score': 488}\n",
            "Episode:36 Score:461 Info:{'opp_score': 451}\n",
            "Episode:37 Score:625 Info:{'opp_score': 365}\n",
            "Episode:38 Score:117 Info:{'opp_score': 567}\n",
            "Episode:39 Score:479 Info:{'opp_score': 444}\n",
            "Episode:40 Score:465 Info:{'opp_score': 465}\n",
            "Episode:41 Score:139 Info:{'opp_score': 574}\n",
            "Episode:42 Score:103 Info:{'opp_score': 613}\n",
            "Episode:43 Score:106 Info:{'opp_score': 601}\n",
            "Episode:44 Score:467 Info:{'opp_score': 462}\n",
            "Episode:45 Score:430 Info:{'opp_score': 430}\n",
            "Episode:46 Score:446 Info:{'opp_score': 506}\n",
            "Episode:47 Score:415 Info:{'opp_score': 475}\n",
            "Episode:48 Score:474 Info:{'opp_score': 469}\n",
            "Episode:49 Score:664 Info:{'opp_score': 389}\n",
            "Episode:50 Score:455 Info:{'opp_score': 455}\n",
            "Episode:51 Score:800 Info:{'opp_score': 300}\n",
            "Episode:52 Score:393 Info:{'opp_score': 433}\n",
            "Episode:53 Score:137 Info:{'opp_score': 557}\n",
            "Episode:54 Score:812 Info:{'opp_score': 282}\n",
            "Episode:55 Score:111 Info:{'opp_score': 571}\n",
            "Episode:56 Score:812 Info:{'opp_score': 282}\n",
            "Episode:57 Score:83 Info:{'opp_score': 678}\n",
            "Episode:58 Score:448 Info:{'opp_score': 443}\n",
            "Episode:59 Score:115 Info:{'opp_score': 550}\n",
            "Episode:60 Score:619 Info:{'opp_score': 384}\n",
            "Episode:61 Score:106 Info:{'opp_score': 591}\n",
            "Episode:62 Score:144 Info:{'opp_score': 569}\n",
            "Episode:63 Score:410 Info:{'opp_score': 440}\n",
            "Episode:64 Score:636 Info:{'opp_score': 386}\n",
            "Episode:65 Score:100 Info:{'opp_score': 610}\n",
            "Episode:66 Score:141 Info:{'opp_score': 591}\n",
            "Episode:67 Score:616 Info:{'opp_score': 356}\n",
            "Episode:68 Score:139 Info:{'opp_score': 584}\n",
            "Episode:69 Score:447 Info:{'opp_score': 467}\n",
            "Episode:70 Score:108 Info:{'opp_score': 583}\n",
            "Episode:71 Score:139 Info:{'opp_score': 614}\n",
            "Episode:72 Score:467 Info:{'opp_score': 467}\n",
            "Episode:73 Score:458 Info:{'opp_score': 453}\n",
            "Episode:74 Score:818 Info:{'opp_score': 273}\n",
            "Episode:75 Score:441 Info:{'opp_score': 471}\n",
            "Episode:76 Score:95 Info:{'opp_score': 630}\n",
            "Episode:77 Score:451 Info:{'opp_score': 451}\n",
            "Episode:78 Score:638 Info:{'opp_score': 363}\n",
            "Episode:79 Score:633 Info:{'opp_score': 363}\n",
            "Episode:80 Score:473 Info:{'opp_score': 468}\n",
            "Episode:81 Score:441 Info:{'opp_score': 441}\n",
            "Episode:82 Score:162 Info:{'opp_score': 557}\n",
            "Episode:83 Score:105 Info:{'opp_score': 595}\n",
            "Episode:84 Score:106 Info:{'opp_score': 586}\n",
            "Episode:85 Score:601 Info:{'opp_score': 411}\n",
            "Episode:86 Score:476 Info:{'opp_score': 476}\n",
            "Episode:87 Score:626 Info:{'opp_score': 381}\n",
            "Episode:88 Score:627 Info:{'opp_score': 367}\n",
            "Episode:89 Score:433 Info:{'opp_score': 448}\n",
            "Episode:90 Score:245 Info:{'opp_score': 485}\n",
            "Episode:91 Score:448 Info:{'opp_score': 448}\n",
            "Episode:92 Score:457 Info:{'opp_score': 452}\n",
            "Episode:93 Score:165 Info:{'opp_score': 590}\n",
            "Episode:94 Score:459 Info:{'opp_score': 459}\n",
            "Episode:95 Score:614 Info:{'opp_score': 399}\n",
            "Episode:96 Score:105 Info:{'opp_score': 615}\n",
            "Episode:97 Score:794 Info:{'opp_score': 309}\n",
            "Episode:98 Score:104 Info:{'opp_score': 599}\n",
            "Episode:99 Score:108 Info:{'opp_score': 578}\n",
            "Episode:100 Score:454 Info:{'opp_score': 449}\n",
            "Win Rate: 0.4\n"
          ]
        }
      ],
      "source": [
        "env = PrisonEnv()\n",
        "episodes = 100\n",
        "done = False\n",
        "score = 0\n",
        "wins=0\n",
        "for episode in range(1,episodes+1):\n",
        "  state=env.reset()\n",
        "  done=False\n",
        "  score=0\n",
        "  while not done:\n",
        "      action = env.action_space.sample()\n",
        "      n_state, reward, done, info = env.step(action)\n",
        "      score+=reward\n",
        "  if info['opp_score'] < score:\n",
        "    wins += 1\n",
        "\n",
        "  print('Episode:{} Score:{} Info:{}'.format(episode, score, info))\n",
        "\n",
        "print('Win Rate:',wins/100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJIFZb40O-E8",
        "outputId": "c0ba643a-a02a-4ef6-f173-b186b3a1039f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KjcbSkClOrjo"
      },
      "outputs": [],
      "source": [
        "states = env.observation_space.shape[0]\n",
        "actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZNE5MNMOrjo",
        "outputId": "7cbb9c16-2b8e-415a-b66c-3966d0600c60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhPOduErOrjp",
        "outputId": "15b27be5-601e-428c-c8cb-c498ff96c88a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z9WusH-TOrjp"
      },
      "outputs": [],
      "source": [
        "def build_model(states, actions):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(1,states)))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(actions, activation='softmax'))\n",
        "    model.add(Flatten())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "njOepqZQOrjp",
        "outputId": "289f9378-99a1-4b7a-9379-613b4a92293e"
      },
      "outputs": [],
      "source": [
        "# del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5yl-npaCOrjp"
      },
      "outputs": [],
      "source": [
        "model = build_model(states, actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnjmS3j4Orjp",
        "outputId": "36cffcc7-538c-4295-b68b-e56e093a0c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1, 128)            1408      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1, 128)            16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1, 128)            16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1, 2)              258       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,690\n",
            "Trainable params: 34,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvI5ZhxmOrjp",
        "outputId": "a82a1fa9-83ea-4608-d47a-099ae01806af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 1, 10)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UpZgtVWwTc4",
        "outputId": "44b629a1-e732-4aac-d3f3-de63d250bfe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fagM9-iwgMcF",
        "outputId": "07464a46-6adc-4429-bd4f-7c64ea4dab3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "M2mljTOnOrjq"
      },
      "outputs": [],
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = BoltzmannQPolicy()\n",
        "    memory = SequentialMemory(limit=50000, window_length=1)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
        "    return dqn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4TrL0bMOrjq",
        "outputId": "279938eb-4524-4821-b636-aaa5d24f31cf"
      },
      "outputs": [],
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),metrics=['mae'])\n",
        "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_ikpNdeY8vYo"
      },
      "outputs": [],
      "source": [
        "scores = dqn.test(env, nb_episodes=100, visualize=False,verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0aBBpPuy1a0",
        "outputId": "f352152b-6879-4a60-b1cc-7a7ef181fcae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Win Rate: 0.87\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "wins=0\n",
        "\n",
        "for episode in range(100):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = dqn.forward(state)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "          if total_reward > info['opp_score']:\n",
        "              wins +=1\n",
        "\n",
        "\n",
        "print(f'Win Rate: {wins/100}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Model (Extra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PUPzGnO4RyxC"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, buffer_size=int(1e5)):\n",
        "        self.buffer = deque(maxlen=buffer_size)\n",
        "\n",
        "    def store(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ec1FwpBNfm8n"
      },
      "outputs": [],
      "source": [
        "class MyDQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = ReplayBuffer()\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(128, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mae', optimizer=tf.keras.optimizers.legacy.Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])\n",
        "\n",
        "    def learn(self, batch_size):\n",
        "        minibatch = self.memory.sample(batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTk7Zp7wfqaO",
        "outputId": "59e74e04-cf86-4aa8-e565-0514102163a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Mohammad Doleh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 1/20, Score: 0, Epsilon: 0.43\n",
            "Episode: 2/20, Score: 0, Epsilon: 0.16\n",
            "Episode: 3/20, Score: 0, Epsilon: 0.059\n",
            "Episode: 4/20, Score: 0, Epsilon: 0.022\n",
            "Episode: 5/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 6/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 7/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 8/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 9/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 10/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 11/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 12/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 13/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 14/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 15/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 16/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 17/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 18/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 19/20, Score: 0, Epsilon: 0.01\n",
            "Episode: 20/20, Score: 0, Epsilon: 0.01\n"
          ]
        }
      ],
      "source": [
        "env = PrisonEnv()\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "agent = MyDQNAgent(state_size, action_size)\n",
        "episodes = 20\n",
        "\n",
        "for e in range(episodes):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    episode_reward=0\n",
        "    for time in range(200):\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        episode_reward += episode_reward\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        agent.memory.store(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        if done:\n",
        "            print(f\"Episode: {e+1}/{episodes}, Score: {episode_reward}, Epsilon: {agent.epsilon:.2}\")\n",
        "            break\n",
        "        if len(agent.memory) > 32:\n",
        "            agent.learn(32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0lO3ZgIgOLl",
        "outputId": "54bc9df2-a015-489d-b750-19be474748f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Episode 1/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 2/100 Reward: 216 Opponent Score: 206\n",
            "Test Episode 3/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 4/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 5/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 6/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 7/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 8/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 9/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 10/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 11/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 12/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 13/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 14/100 Reward: 216 Opponent Score: 206\n",
            "Test Episode 15/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 16/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 17/100 Reward: 583 Opponent Score: 118\n",
            "Test Episode 18/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 19/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 20/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 21/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 22/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 23/100 Reward: 508 Opponent Score: 508\n",
            "Test Episode 24/100 Reward: 793 Opponent Score: 63\n",
            "Test Episode 25/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 26/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 27/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 28/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 29/100 Reward: 793 Opponent Score: 63\n",
            "Test Episode 30/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 31/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 32/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 33/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 34/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 35/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 36/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 37/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 38/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 39/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 40/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 41/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 42/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 43/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 44/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 45/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 46/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 47/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 48/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 49/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 50/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 51/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 52/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 53/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 54/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 55/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 56/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 57/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 58/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 59/100 Reward: 216 Opponent Score: 206\n",
            "Test Episode 60/100 Reward: 630 Opponent Score: 105\n",
            "Test Episode 61/100 Reward: 602 Opponent Score: 112\n",
            "Test Episode 62/100 Reward: 216 Opponent Score: 206\n",
            "Test Episode 63/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 64/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 65/100 Reward: 578 Opponent Score: 118\n",
            "Test Episode 66/100 Reward: 793 Opponent Score: 63\n",
            "Test Episode 67/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 68/100 Reward: 561 Opponent Score: 121\n",
            "Test Episode 69/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 70/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 71/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 72/100 Reward: 793 Opponent Score: 63\n",
            "Test Episode 73/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 74/100 Reward: 793 Opponent Score: 63\n",
            "Test Episode 75/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 76/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 77/100 Reward: 594 Opponent Score: 114\n",
            "Test Episode 78/100 Reward: 609 Opponent Score: 109\n",
            "Test Episode 79/100 Reward: 548 Opponent Score: 128\n",
            "Test Episode 80/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 81/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 82/100 Reward: 506 Opponent Score: 511\n",
            "Test Episode 83/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 84/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 85/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 86/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 87/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 88/100 Reward: 216 Opponent Score: 206\n",
            "Test Episode 89/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 90/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 91/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 92/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 93/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 94/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 95/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 96/100 Reward: 212 Opponent Score: 207\n",
            "Test Episode 97/100 Reward: 499 Opponent Score: 514\n",
            "Test Episode 98/100 Reward: 992 Opponent Score: 12\n",
            "Test Episode 99/100 Reward: 509 Opponent Score: 509\n",
            "Test Episode 100/100 Reward: 216 Opponent Score: 206\n",
            "Win Rate: 0.72\n"
          ]
        }
      ],
      "source": [
        "agent.epsilon = 0\n",
        "test_episodes = 100\n",
        "wins=0\n",
        "\n",
        "for episode in range(test_episodes):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    episode_reward = 0\n",
        "\n",
        "    for t in range(500):\n",
        "        action = agent.act(state)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        state = np.reshape(state, [1, state_size])\n",
        "        episode_reward += reward\n",
        "\n",
        "        if done:\n",
        "          if episode_reward > info['opp_score']:\n",
        "            wins += 1\n",
        "            break\n",
        "\n",
        "    print(f\"Test Episode {episode+1}/{test_episodes} Reward: {episode_reward} Opponent Score: {info['opp_score']}\")\n",
        "\n",
        "print(f\"Win Rate: {wins/100}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
